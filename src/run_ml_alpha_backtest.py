"""
Backtesting script for the ML-driven Alpha-Aware CVaR Strategy.

This script runs a rolling backtest using alpha signals generated by the MLAlphaModel.
The model is retrained at each rebalancing period to adapt to new market data.
"""

import logging
import pandas as pd
import numpy as np
import os
from dotenv import load_dotenv
from tqdm import tqdm
import asyncio

from src.alpha.fmp_signals import FmpPremiumSignals
from src.data.processor import DataProcessor
from src.alpha.ml_model import MLAlphaModel, build_feature_target_set
from src.alpha.signal_processor import DynamicSignalProcessor
from src.optimization.cvar_optimizer import AlphaAwareCVaROptimizer
from src.backtesting.engine import BacktestEngine
from src.backtesting.metrics import calculate_raw_metrics, format_metrics_for_display, update_consolidated_returns

# --- Configuration ---
LOG_LEVEL = logging.INFO
logging.basicConfig(level=LOG_LEVEL, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Environment Setup ---
load_dotenv()
FMP_API_KEY = os.getenv('FMP_API_KEY')
if not FMP_API_KEY:
    logging.error("FMP_API_KEY not found in .env file.")
    exit()

# --- File Paths ---
RESULTS_DIR = 'd:/Quantoro/results'
PRICE_DATA_PATH = os.path.join(RESULTS_DIR, 'sp500_prices_2010_2024.csv')
OUTPUT_WEIGHTS_PATH = os.path.join(RESULTS_DIR, 'ml_alpha_weights.csv')
OUTPUT_RETURNS_PATH = os.path.join(RESULTS_DIR, 'ml_alpha_returns.csv')
OUTPUT_METRICS_PATH = os.path.join(RESULTS_DIR, 'ml_alpha_metrics.csv')


def build_feature_target_set(current_date, returns_data, raw_fmp_signals, lookback_days, forward_days):
    """Builds a feature and target set for a given time window."""
    start_date = current_date - pd.Timedelta(days=lookback_days)
    end_date = current_date
    
    # Use a signal processor to generate time-aware FMP features
    fmp_processor = DynamicSignalProcessor(raw_fmp_signals)
    
    all_features = []
    all_targets = []
    
    # Generate features for each day in the lookback window
    date_range = pd.date_range(start=start_date, end=end_date, freq='B') # Business days
    for date in tqdm(date_range, desc="Building training set", leave=False):
        if date not in returns_data.index:
            continue
            
        # 1. FMP Features
        fmp_scores = fmp_processor.generate_time_aware_alpha_scores(date)['alpha_score']
        
        # 2. Momentum Features (1-month, 3-month, 12-month)
        mom_1m = returns_data.loc[:date].tail(21).mean() * 252
        mom_3m = returns_data.loc[:date].tail(63).mean() * 252
        mom_12m = returns_data.loc[:date].tail(252).mean() * 252
        
        # 3. Target: Forward Returns
        future_start = returns_data.index.searchsorted(date) + 1
        future_end = future_start + forward_days
        if future_end > len(returns_data):
            continue
        forward_returns = returns_data.iloc[future_start:future_end].sum()
        
        # Combine and align
        features_for_date = pd.concat([
            fmp_scores.rename('fmp_alpha'),
            mom_1m.rename('mom_1m'),
            mom_3m.rename('mom_3m'),
            mom_12m.rename('mom_12m')
        ], axis=1)
        
        combined = pd.concat([features_for_date, forward_returns.rename('target')], axis=1).dropna()
        all_features.append(combined.drop(columns='target'))
        all_targets.append(combined['target'])

    if not all_features:
        return pd.DataFrame(), pd.Series(dtype=np.float64)
        
    return pd.concat(all_features), pd.concat(all_targets)

def get_prediction_features(current_date, returns_data, raw_fmp_signals):
    """Generates features for the current date for prediction."""
    fmp_processor = DynamicSignalProcessor(raw_fmp_signals)
    fmp_scores = fmp_processor.generate_time_aware_alpha_scores(current_date)['alpha_score']
    mom_1m = returns_data.loc[:current_date].tail(21).mean() * 252
    mom_3m = returns_data.loc[:current_date].tail(63).mean() * 252
    mom_12m = returns_data.loc[:current_date].tail(252).mean() * 252
    
    features = pd.concat([
        fmp_scores.rename('fmp_alpha'),
        mom_1m.rename('mom_1m'),
        mom_3m.rename('mom_3m'),
        mom_12m.rename('mom_12m')
    ], axis=1).dropna()
    features.index.name = 'ticker'
    return features

def main():
    """Main function to run the ML alpha backtest."""
    logging.info("--- Starting ML-Driven Alpha-Aware CVaR Backtest ---")

    price_data = pd.read_csv(PRICE_DATA_PATH, index_col='date', parse_dates=True)
    universe = price_data.columns.tolist()
    data_processor = DataProcessor()
    returns_data = data_processor.calculate_returns(price_data, log_returns=False)

    logging.info("Fetching raw FMP signals...")
    signal_fetcher = FmpPremiumSignals(api_key=FMP_API_KEY)
    logging.info("Fetching raw FMP signals with reduced concurrency...")
    # Reduce concurrency to improve stability during data fetching
    raw_fmp_signals = asyncio.run(signal_fetcher.get_all_signals_for_universe(
        tickers=universe,
        concurrency_limit=2
    ))
    logging.info("FMP signals fetched.")

    optimizer = AlphaAwareCVaROptimizer(
        alpha=0.95, 
        lasso_penalty=0.01, 
        max_weight=0.1,
        alpha_factor=0.05  # Weight for the ML alpha signal in the objective
    )
    ml_alpha_model = MLAlphaModel(lookahead_period=63)

    backtest_engine = BacktestEngine(
        returns_data=returns_data,
        optimizer=optimizer,
        start_date='2020-01-01',
        end_date='2024-12-31',
        rebalance_frequency='Q'  # Use 'Q' for quarterly frequency
    )

    all_weights = {}
    last_model = None
    last_feature_names = []

    for rebalance_date, returns_window in backtest_engine.run_rolling_backtest():
        logging.info(f"--- Processing rebalance date: {rebalance_date.date()} ---")

        # 1. Build training set from the last 2 years of data
        X_train, y_train = build_feature_target_set(
            current_date=rebalance_date,
            returns_data=returns_data,
            raw_fmp_signals=raw_fmp_signals,
            lookback_days=504, # Roughly 2 years of trading days
            forward_days=ml_alpha_model.lookahead_period
        )

        if X_train.empty:
            logging.warning(f"Could not build training set for {rebalance_date.date()}. Skipping.")
            all_weights[rebalance_date] = backtest_engine.get_previous_weights()
            continue

        # 2. Train the ML model (handles scaling internally)
        ml_alpha_model.train_model(X_train, y_train)
        last_feature_names = ml_alpha_model.feature_names

        # 3. Build features for prediction (using data up to the rebalance date)
        X_pred = get_prediction_features(
            current_date=rebalance_date,
            returns_data=returns_data,
            raw_fmp_signals=raw_fmp_signals
        )
        
        if X_pred.empty:
            logging.warning(f"No features for prediction on {rebalance_date.date()}. Using zero alpha.")
            alpha_scores = pd.Series(0, index=returns_window.columns)
        else:
            # 4. Predict alpha scores (handles scaling internally)
            alpha_scores = ml_alpha_model.predict_alpha(X_pred)

        # 5. Run optimization
        result = backtest_engine.rebalance(rebalance_date, returns_window, alpha_scores=alpha_scores)
        all_weights[rebalance_date] = result
        last_model = ml_alpha_model.model.booster_

    if not all_weights:
        logging.error("Backtest generated no weights. Halting.")
        return

    # Save the last trained model and feature names for analysis
    if last_model:
        model_path = os.path.join(RESULTS_DIR, 'ml_alpha_model.txt')
        last_model.save_model(model_path)
        logging.info(f"Saved final ML model to {model_path}")

        import json
        features_path = os.path.join(RESULTS_DIR, 'ml_alpha_feature_names.json')
        with open(features_path, 'w') as f:
            json.dump(last_feature_names, f)
        logging.info(f"Saved feature names to {features_path}")

    logging.info("Calculating performance metrics...")
    weights_df = pd.DataFrame.from_dict(all_weights, orient='index', columns=universe).fillna(0)
    
    # Calculate portfolio returns (shifting weights to avoid lookahead bias)
    aligned_weights = weights_df.reindex(returns_data.index, method='ffill')
    portfolio_returns = (returns_data * aligned_weights.shift(1)).sum(axis=1)
    
    # CRITICAL FIX: Slice returns to the actual backtest period to ensure metrics are correct
    portfolio_returns = portfolio_returns.loc[backtest_engine.start_date:backtest_engine.end_date].dropna()

    # Load benchmark returns for metrics calculation
    if 'SPY' in price_data.columns:
        benchmark_prices = price_data['SPY']
        benchmark_returns = data_processor.calculate_returns(benchmark_prices.to_frame(), log_returns=False).squeeze()
        benchmark_returns = benchmark_returns.reindex(portfolio_returns.index).fillna(0)
        logging.info("SPY benchmark loaded for metrics calculation.")
    else:
        logging.warning("SPY benchmark not found. Alpha and Beta will be NaN.")
        benchmark_returns = pd.Series(0.0, index=portfolio_returns.index)

    performance_metrics = calculate_raw_metrics(
        portfolio_returns=portfolio_returns,
        benchmark_returns=benchmark_returns
    )

    # Format for display
    formatted_metrics = format_metrics_for_display(
        raw_metrics=performance_metrics, 
        portfolio_returns=portfolio_returns
    )

    # Update the consolidated returns file for reporting
    update_consolidated_returns(
        new_returns=portfolio_returns,
        strategy_name='ML_Alpha_CVaR',
        output_path=os.path.join(RESULTS_DIR, 'daily_returns.csv')
    )

    # Save results
    weights_df.to_csv(OUTPUT_WEIGHTS_PATH)
    portfolio_returns.to_csv(OUTPUT_RETURNS_PATH)
    performance_metrics.to_csv(OUTPUT_METRICS_PATH)
    logging.info(f"Results saved to {RESULTS_DIR}")

    print("\n--- ML Alpha-Aware Performance Metrics ---")
    print(formatted_metrics)
    logging.info("--- Backtest Complete ---")

if __name__ == "__main__":
    main()
